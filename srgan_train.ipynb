{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Super-Resolution Generative Adversarial Network training**\n",
    "\n",
    "Here in this jupyter notebook, we will train a super-resolution generative adversarial network (SRGAN), to create a high-resolution Antarctic bed Digital Elevation Model(DEM) from a low-resolution DEM.\n",
    "In addition to that, we use additional correlated inputs that can also tell us something about the bed topography.\n",
    "\n",
    "<img src=\"https://yuml.me/diagram/scruffy;dir:LR/class/[BEDMAP2 (1000m)]->[Generator model],[REMA (100m)]->[Generator model],[MEASURES Ice Flow Velocity (450m)]->[Generator model],[Generator model]->[High res bed DEM (250m)],[High res bed DEM (250m)]->[Discriminator model],[Groundtruth Image (250m)]->[Discriminator model],[Discriminator model]->[True/False]\" alt=\"3 input SRGAN model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python       : 3.6.6 | packaged by conda-forge | (default, Oct 11 2018, 14:33:06) \n",
      "Numpy        : 1.14.5\n",
      "Chainer      : 6.0.0b1\n",
      "Keras        : 2.2.4\n",
      "Tensorflow   : 1.10.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import typing\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import comet_ml\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quilt\n",
    "import skimage.transform\n",
    "import tqdm\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import cupy\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import (\n",
    "    Add,\n",
    "    BatchNormalization,\n",
    "    Concatenate,\n",
    "    Conv2D,\n",
    "    Conv2DTranspose,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Lambda,\n",
    ")\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "import livelossplot\n",
    "\n",
    "from features.environment import _load_ipynb_modules\n",
    "\n",
    "print(\"Python       :\", sys.version.split(\"\\n\")[0])\n",
    "print(\"Numpy        :\", np.__version__)\n",
    "print(\"Chainer      :\", chainer.__version__)\n",
    "print(\"Keras        :\", keras.__version__)\n",
    "print(\"Tensorflow   :\", K.tf.__version__)\n",
    "K.tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed values\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed(seed=seed)\n",
    "# cupy.random.seed(seed=seed)\n",
    "K.tf.set_random_seed(seed=seed)\n",
    "\n",
    "# Start tracking experiment using Comet.ML\n",
    "experiment = comet_ml.Experiment(\n",
    "    workspace=\"weiji14\", project_name=\"deepbedmap\", disabled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading package metadata...\n",
      "Fragments already downloaded\n"
     ]
    }
   ],
   "source": [
    "hash = \"1ccc9dc7f6344e1ec27b7aa972f2739d192d3e5adef8a64528b86bc799e2df60\"\n",
    "quilt.install(package=\"weiji14/deepbedmap/model/train\", hash=hash, force=True)\n",
    "pkg = quilt.load(pkginfo=\"weiji14/deepbedmap/model/train\", hash=hash)\n",
    "experiment.log_parameter(\"dataset_hash\", hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2480, 100, 100, 1) (2480, 20, 20, 1) (2480, 10, 10, 1) (2480, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "W1_data = pkg.W1_data()  # miscellaneous data REMA\n",
    "W2_data = pkg.W2_data()  # miscellaneous data MEASURES Ice Flow\n",
    "X_data = pkg.X_data()  # low resolution BEDMAP2\n",
    "Y_data = pkg.Y_data()  # high resolution groundtruth\n",
    "# W1_data = np.load(file=\"model/train/W1_data.npy\")\n",
    "# W2_data = np.load(file=\"model/train/W2_data.npy\")\n",
    "# X_data = np.load(file=\"model/train/X_data.npy\")\n",
    "# Y_data = np.load(file=\"model/train/Y_data.npy\")\n",
    "print(W1_data.shape, W2_data.shape, X_data.shape, Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Convert arrays for Chainer\n",
    "- From Numpy (CPU) to CuPy (GPU) format\n",
    "- From NHWC format to NCHW format, where N=number of tiles, H=height, W=width, C=channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "# Detect if there is a CUDA GPU first\n",
    "try:\n",
    "    cupy.cuda.get_device_id()\n",
    "    xp = cupy\n",
    "    print(\"Using GPU\")\n",
    "\n",
    "    W1_data = chainer.backend.cuda.to_gpu(array=W1_data)\n",
    "    W2_data = chainer.backend.cuda.to_gpu(array=W2_data)\n",
    "    X_data = chainer.backend.cuda.to_gpu(array=X_data)\n",
    "    Y_data = chainer.backend.cuda.to_gpu(array=Y_data)\n",
    "except:  # CUDARuntimeError\n",
    "    xp = np\n",
    "    print(\"Using CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2480, 1, 100, 100) (2480, 1, 20, 20) (2480, 1, 10, 10) (2480, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "W1_data = xp.rollaxis(a=W1_data, axis=3, start=1)\n",
    "W2_data = xp.rollaxis(a=W2_data, axis=3, start=1)\n",
    "X_data = xp.rollaxis(a=X_data, axis=3, start=1)\n",
    "Y_data = xp.rollaxis(a=Y_data, axis=3, start=1)\n",
    "print(W1_data.shape, W2_data.shape, X_data.shape, Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Split dataset into training (train) and development (dev) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: 2356 tiles, Test dataset: 124 tiles\n"
     ]
    }
   ],
   "source": [
    "dataset = chainer.datasets.DictDataset(X=X_data, W1=W1_data, W2=W2_data, Y=Y_data)\n",
    "train_set, dev_set = chainer.datasets.split_dataset_random(\n",
    "    dataset=dataset, first_size=int(len(X_data) * 0.95), seed=seed\n",
    ")\n",
    "print(f\"Training dataset: {len(train_set)} tiles, Test dataset: {len(dev_set)} tiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_iter = chainer.iterators.SerialIterator(\n",
    "    dataset=train_set, batch_size=batch_size, repeat=True, shuffle=True\n",
    ")\n",
    "dev_iter = chainer.iterators.SerialIterator(\n",
    "    dataset=dev_set, batch_size=batch_size, repeat=True, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Architect model **(Note: Work in Progress!!)**\n",
    "\n",
    "Enhanced Super Resolution Generative Adversarial Network (ESRGAN) model based on [Wang et al. 2018](https://arxiv.org/abs/1809.00219v2).\n",
    "Refer to original Pytorch implementation at https://github.com/xinntao/ESRGAN.\n",
    "See also previous (non-enhanced) SRGAN model architecture by [Ledig et al. 2017](https://arxiv.org/abs/1609.04802)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Generator Network Architecture\n",
    "\n",
    "![ESRGAN architecture - Generator Network composed of many Dense Convolutional Blocks](https://github.com/xinntao/ESRGAN/raw/master/figures/architecture.jpg)\n",
    "\n",
    "3 main components: 1) Input Block, 2) Residual Blocks, 3) Upsampling Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Input block, specially customized for DeepBedMap to take in 3 different inputs\n",
    "\n",
    "Details of the first convolutional layer for each input:\n",
    "\n",
    "- Input tiles are 8000m by 8000m.\n",
    "- Convolution filter kernels are 3000m by 3000m.\n",
    "- Strides are 1000m by 1000m.\n",
    "\n",
    "Example: for a 100m spatial resolution tile:\n",
    "\n",
    "- Input tile is 80pixels by 80pixels\n",
    "- Convolution filter kernels are 30pixels by 30pixels\n",
    "- Strides are 10pixels by 10pixels\n",
    "\n",
    "Note that these first convolutional layers uses '**valid**' padding, see https://keras.io/layers/convolutional/ for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class DeepbedmapInputBlock(chainer.Chain):\n",
    "    \"\"\"\n",
    "    Custom input block for DeepBedMap.\n",
    "\n",
    "    Each filter kernel is 3km by 3km in size, with a 1km stride and no padding.\n",
    "    So for a 1km resolution image, (i.e. 1km pixel size):\n",
    "    kernel size is (3, 3), stride is (1, 1), and pad is (0, 0)\n",
    "\n",
    "      (?,1,10,10) --Conv2D-- (?,32,8,8) \\\n",
    "    (?,1,100,100) --Conv2D-- (?,32,8,8) --Concat-- (?,96,8,8)\n",
    "      (?,1,20,20) --Conv2D-- (?,32,8,8) /\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, out_channels=32):\n",
    "        super().__init__()\n",
    "        init_weights = chainer.initializers.GlorotUniform(scale=1.0)\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.conv_on_X = L.Convolution2D(\n",
    "                in_channels=1,\n",
    "                out_channels=out_channels,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=(0, 0),  # 'valid' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "            self.conv_on_W1 = L.Convolution2D(\n",
    "                in_channels=1,\n",
    "                out_channels=out_channels,\n",
    "                ksize=(30, 30),\n",
    "                stride=(10, 10),\n",
    "                pad=(0, 0),  # 'valid' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "            self.conv_on_W2 = L.Convolution2D(\n",
    "                in_channels=1,\n",
    "                out_channels=out_channels,\n",
    "                ksize=(6, 6),\n",
    "                stride=(2, 2),\n",
    "                pad=(0, 0),  # 'valid' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "\n",
    "    def forward(self, x, w1, w2):\n",
    "        \"\"\"\n",
    "        Forward computation, i.e. evaluate based on inputs X, W1 and W2\n",
    "        \"\"\"\n",
    "        x_ = self.conv_on_X(x)\n",
    "        w1_ = self.conv_on_W1(w1)\n",
    "        w2_ = self.conv_on_W2(w2)\n",
    "\n",
    "        a = F.concat(xs=(x_, w1_, w2_))\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Residual Block\n",
    "\n",
    "![The Residual in Residual Dense Block in detail](https://arxiv-sanity-sanity-production.s3.amazonaws.com/render-output/518727/x4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(chainer.Chain):\n",
    "    \"\"\"\n",
    "    Residual block made of Convoutional2D-LeakyReLU-Convoutional2D layers\n",
    "\n",
    "       -----------------------------\n",
    "      |                             |\n",
    "    -----Conv2D--LeakyReLu--Conv2D-(+)--\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, out_channels=64):\n",
    "        super().__init__()\n",
    "        init_weights = chainer.initializers.GlorotUniform(scale=1.0)\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.conv_layer1 = L.Convolution2D(\n",
    "                in_channels=None,\n",
    "                out_channels=out_channels,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=1,  # 'same' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "            self.conv_layer2 = L.Convolution2D(\n",
    "                in_channels=out_channels,\n",
    "                out_channels=out_channels,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=1,  # 'same' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward computation, i.e. evaluate based on input x\n",
    "        \"\"\"\n",
    "        a = self.conv_layer1(x)\n",
    "        a = F.leaky_relu(x=a, slope=0.2)\n",
    "        a = self.conv_layer2(a)\n",
    "\n",
    "        a = F.add(x, a)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Build the Generator Network, with upsampling layers!\n",
    "\n",
    "![3 inputs feeding into the Generator Network, producing a high resolution prediction output](https://yuml.me/dffffcb0.png)\n",
    "\n",
    "<!--[W2_input(MEASURES)|20x20x1]-k6n32s2>[W2_inter|8x8x32],[W2_inter]->[Concat|8x8x96]\n",
    "[X_input(BEDMAP2)|10x10x1]-k3n32s1>[X_inter|8x8x32],[X_inter]->[Concat|8x8x96]\n",
    "[W1_input(REMA)|100x100x1]-k30n32s10>[W1_inter|8x8x32],[W1_inter]->[Concat|8x8x96]\n",
    "[Concat|8x8x96]->[Generator-Network|Many-Residual-Blocks],[Generator-Network]->[Y_hat(High-Resolution_DEM)|32x32x1]-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class GeneratorModel(chainer.Chain):\n",
    "    \"\"\"\n",
    "    The generator network which is a deconvolutional neural network.\n",
    "    Converts a low resolution input into a super resolution output.\n",
    "\n",
    "    Glues the input block with several residual blocks and upsampling layers\n",
    "\n",
    "    Parameters:\n",
    "      input_shape -- shape of input tensor in tuple format (height, width, channels)\n",
    "      num_residual_blocks -- how many Conv-LeakyReLU-Conv blocks to use\n",
    "      scaling -- even numbered integer to increase resolution (e.g. 0, 2, 4, 6, 8)\n",
    "      out_channels -- integer representing number of output channels/filters/kernels\n",
    "\n",
    "    Example:\n",
    "      An input_shape of (8,8,1) passing through 16 residual blocks with a scaling of 4\n",
    "      and output_channels 1 will result in an image of shape (32,32,1)\n",
    "\n",
    "    >>> generator_model = GeneratorModel(\n",
    "    ...     inblock_class=DeepbedmapInputBlock,\n",
    "    ...     resblock_class=ResidualBlock,\n",
    "    ...     num_residual_blocks=16,\n",
    "    ... )\n",
    "    >>> y_pred = generator_model.forward(\n",
    "    ...     inputs={\n",
    "    ...         \"x\": np.random.rand(1, 1, 10, 10).astype(\"float32\"),\n",
    "    ...         \"w1\": np.random.rand(1, 1, 100, 100).astype(\"float32\"),\n",
    "    ...         \"w2\": np.random.rand(1, 1, 20, 20).astype(\"float32\"),\n",
    "    ...     }\n",
    "    ... )\n",
    "    >>> y_pred.shape\n",
    "    (1, 1, 32, 32)\n",
    "    >>> generator_model.count_params()\n",
    "    1604929\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inblock_class,\n",
    "        resblock_class,\n",
    "        num_residual_blocks: int = 16,\n",
    "        out_channels: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        init_weights = chainer.initializers.GlorotUniform(scale=1.0)\n",
    "\n",
    "        with self.init_scope():\n",
    "\n",
    "            # Initial Input and Residual Blocks\n",
    "            self.input_block = inblock_class()\n",
    "            self.pre_residual_conv_layer = L.Convolution2D(\n",
    "                in_channels=None,\n",
    "                out_channels=64,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=1,  # 'same' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "            self.residual_network = resblock_class().repeat(\n",
    "                n_repeat=num_residual_blocks\n",
    "            )\n",
    "            self.post_residual_conv_layer = L.Convolution2D(\n",
    "                in_channels=None,\n",
    "                out_channels=64,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=1,  # 'same' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "\n",
    "            # Upsampling Layers\n",
    "            self.pre_upsample_conv_layer_1 = L.Convolution2D(\n",
    "                in_channels=None,\n",
    "                out_channels=256,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=1,  # 'same' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "            self.pre_upsample_conv_layer_2 = L.Convolution2D(\n",
    "                in_channels=None,\n",
    "                out_channels=256,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=1,  # 'same' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "            self.post_upsample_conv_layer = L.Convolution2D(\n",
    "                in_channels=None,\n",
    "                out_channels=out_channels,\n",
    "                ksize=(9, 9),\n",
    "                stride=(1, 1),\n",
    "                pad=4,  # 'same' padding\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "\n",
    "    def forward(self, inputs: dict):\n",
    "        \"\"\"\n",
    "        Forward computation, i.e. evaluate based on inputs\n",
    "\n",
    "        Input dictionary needs to have keys \"x\", \"w1\", \"w2\"\n",
    "        \"\"\"\n",
    "        # 0 part\n",
    "        # Resize inputs o right scale using convolution (hardcoded kernel_size and strides)\n",
    "        # Also concatenate all inputs\n",
    "        a0 = self.input_block(x=inputs[\"x\"], w1=inputs[\"w1\"], w2=inputs[\"w2\"])\n",
    "\n",
    "        # 1st part\n",
    "        # Pre-residual k3n64s1 (originally k9n64s1)\n",
    "        a1 = self.pre_residual_conv_layer(a0)\n",
    "        a1 = F.leaky_relu(x=a1, slope=0.2)\n",
    "\n",
    "        # 2nd part\n",
    "        # Residual blocks k3n64s1\n",
    "        a2 = self.residual_network(a1)\n",
    "\n",
    "        # 3rd part\n",
    "        # Post-residual blocks k3n64s1\n",
    "        a3 = self.post_residual_conv_layer(a2)\n",
    "        a3 = F.add(a1, a3)\n",
    "\n",
    "        # 4th part\n",
    "        # Upsampling (if 4; run twice, if 8; run thrice, etc.) k3n256s1\n",
    "        a4_1 = self.pre_upsample_conv_layer_1(a3)\n",
    "        a4_1 = F.depth2space(X=a4_1, r=2)\n",
    "        a4_1 = F.leaky_relu(x=a4_1, slope=0.2)\n",
    "        a4_2 = self.pre_upsample_conv_layer_2(a4_1)\n",
    "        a4_2 = F.depth2space(X=a4_2, r=2)\n",
    "        a4_2 = F.leaky_relu(x=a4_2, slope=0.2)\n",
    "\n",
    "        # 5th part\n",
    "        # Generate high resolution output k9n1s1 (originally k9n3s1 for RGB image)\n",
    "        a5 = self.post_upsample_conv_layer(a4_2)\n",
    "\n",
    "        return a5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def generator_network(\n",
    "    input1_shape: typing.Tuple[int, int, int] = (10, 10, 1),\n",
    "    input2_shape: typing.Tuple[int, int, int] = (100, 100, 1),\n",
    "    input3_shape: typing.Tuple[int, int, int] = (20, 20, 1),\n",
    "    num_residual_blocks: int = 16,\n",
    "    scaling: int = 4,\n",
    "    output_channels: int = 1,\n",
    ") -> keras.engine.network.Network:\n",
    "    \"\"\"\n",
    "    The generator network which is a deconvolutional neural network.\n",
    "    Converts a low resolution input into a super resolution output.\n",
    "\n",
    "    Parameters:\n",
    "      input_shape -- shape of input tensor in tuple format (height, width, channels)\n",
    "      num_residual_blocks -- how many Conv-LeakyReLU-Conv blocks to use\n",
    "      scaling -- even numbered integer to increase resolution (e.g. 0, 2, 4, 6, 8)\n",
    "      output_channels -- integer representing number of output channels/filters/kernels\n",
    "\n",
    "    Example:\n",
    "      An input_shape of (8,8,1) passing through 16 residual blocks with a scaling of 4\n",
    "      and output_channels 1 will result in an image of shape (32,32,1)\n",
    "\n",
    "    >>> generator_network().input_shape\n",
    "    [(None, 10, 10, 1), (None, 100, 100, 1), (None, 20, 20, 1)]\n",
    "    >>> generator_network().output_shape\n",
    "    (None, 32, 32, 1)\n",
    "    >>> generator_network().count_params()\n",
    "    1604929\n",
    "    \"\"\"\n",
    "\n",
    "    assert num_residual_blocks >= 1  # ensure that we have 1 or more residual blocks\n",
    "    assert scaling % 2 == 0  # ensure scaling factor is even, i.e. 0, 2, 4, 8, etc\n",
    "    assert scaling >= 0  # ensure that scaling factor is zero or a positive number\n",
    "    assert output_channels >= 1  # ensure that we have 1 or more output channels\n",
    "\n",
    "    ## Input images\n",
    "    inp1 = Input(shape=input1_shape)  # low resolution image\n",
    "    assert inp1.shape.ndims == 4  # has to be shape like (?,10,10,1) for 10x10 grid\n",
    "    inp2 = Input(shape=input2_shape)  # other image (e.g. REMA)\n",
    "    assert inp2.shape.ndims == 4  # has to be shape like (?,100,100,1) for 100x100 grid\n",
    "    inp3 = Input(shape=input3_shape)  # other image (MEASURES Ice Flow)\n",
    "    assert inp3.shape.ndims == 4  # has to be shape like (?,20,20,1) for 20x20 grid\n",
    "\n",
    "    # 0 part\n",
    "    # Resize inputs to right scale using convolution (hardcoded kernel_size and strides)\n",
    "    inp1r = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\")(\n",
    "        inp1\n",
    "    )\n",
    "    inp2r = Conv2D(filters=32, kernel_size=(30, 30), strides=(10, 10), padding=\"valid\")(\n",
    "        inp2\n",
    "    )\n",
    "    inp3r = Conv2D(filters=32, kernel_size=(6, 6), strides=(2, 2), padding=\"valid\")(\n",
    "        inp3\n",
    "    )\n",
    "\n",
    "    # Concatenate all inputs\n",
    "    # SEE https://distill.pub/2016/deconv-checkerboard/\n",
    "    X = Concatenate()([inp1r, inp2r, inp3r])  # Concatenate all the inputs together\n",
    "\n",
    "    # 1st part\n",
    "    # Pre-residual k3n64s1 (originally k9n64s1)\n",
    "    X0 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(X)\n",
    "    X0 = LeakyReLU(alpha=0.2)(X0)\n",
    "\n",
    "    # 2nd part\n",
    "    # Residual blocks k3n64s1\n",
    "    def residual_block(input_tensor):\n",
    "        x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(\n",
    "            input_tensor\n",
    "        )\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(x)\n",
    "        return Add()([x, input_tensor])\n",
    "\n",
    "    X = residual_block(X0)\n",
    "    for _ in range(num_residual_blocks - 1):\n",
    "        X = residual_block(X)\n",
    "\n",
    "    # 3rd part\n",
    "    # Post-residual blocks k3n64s1\n",
    "    X = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(X)\n",
    "    X = Add()([X, X0])\n",
    "\n",
    "    # 4th part\n",
    "    # Upsampling (if 4; run twice, if 8; run thrice, etc.) k3n256s1\n",
    "    for p, _ in enumerate(range(scaling // 2), start=1):\n",
    "        X = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(X)\n",
    "        pixelshuffleup = lambda images: K.tf.depth_to_space(input=images, block_size=2)\n",
    "        X = Lambda(function=pixelshuffleup, name=f\"pixelshuffleup_{p}\")(X)\n",
    "        X = LeakyReLU(alpha=0.2)(X)\n",
    "\n",
    "    # 5th part\n",
    "    # Generate high resolution output k9n1s1 (originally k9n3s1 for RGB image)\n",
    "    outp = Conv2D(\n",
    "        filters=output_channels,\n",
    "        kernel_size=(9, 9),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        name=\"generator_output\",\n",
    "    )(X)\n",
    "\n",
    "    # Create neural network with input low-res images and output prediction\n",
    "    network = keras.engine.network.Network(\n",
    "        inputs=[inp1, inp2, inp3], outputs=[outp], name=\"generator_network\"\n",
    "    )\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Discriminator Network Architecture\n",
    "\n",
    "Discriminator component is based on Deep Convolutional Generative Adversarial Networks by [Radford et al., 2015](https://arxiv.org/abs/1511.06434).\n",
    "\n",
    "Note that figure below shows the 2017 (non-enhanced) SRGAN discriminator neural network architecture.\n",
    "The 2018 ESRGAN version is basically the same architecture, as only the loss function was changed.\n",
    "Note that the BatchNormalization layers **are still preserved** within the Convolutional blocks (see relevant line in original Pytorch implementation [here](https://github.com/xinntao/BasicSR/blob/902b4ae1f4beec7359de6e62ed0aebfc335d8dfd/codes/models/modules/architecture.py#L88)).\n",
    "\n",
    "![SRGAN architecture - Discriminator Network](https://arxiv-sanity-sanity-production.s3.amazonaws.com/render-output/399644/images/used/jpg/discriminator.jpg)\n",
    "\n",
    "![Discriminator Network](https://yuml.me/diagram/scruffy/class/[High-Resolution_DEM|32x32x1]->[Discriminator-Network],[Discriminator-Network]->[False/True|0/1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class DiscriminatorModel(chainer.Chain):\n",
    "    \"\"\"\n",
    "    The discriminator network which is a convolutional neural network.\n",
    "    Takes ONE high resolution input image and predicts whether it is\n",
    "    real or fake on a scale of 0 to 1, where 0 is fake and 1 is real.\n",
    "\n",
    "    Consists of several Conv2D-BatchNorm-LeakyReLU blocks, followed by\n",
    "    a fully connected linear layer with LeakyReLU activation and a final\n",
    "    fully connected linear layer with Sigmoid activation.\n",
    "\n",
    "    >>> discriminator_model = DiscriminatorModel()\n",
    "    >>> y_pred = discriminator_model.forward(\n",
    "    ...     inputs={\n",
    "    ...         \"x\": np.random.rand(2, 1, 32, 32).astype(\"float32\"),\n",
    "    ...     }\n",
    "    ... )\n",
    "    >>> y_pred.shape\n",
    "    (2, 1)\n",
    "    >>> discriminator_model.count_params()\n",
    "    6824193\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        init_weights = chainer.initializers.GlorotUniform(scale=1.0)\n",
    "\n",
    "        with self.init_scope():\n",
    "\n",
    "            self.conv_layer0 = L.Convolution2D(\n",
    "                in_channels=None,\n",
    "                out_channels=64,\n",
    "                ksize=(3, 3),\n",
    "                stride=(1, 1),\n",
    "                pad=1,  # 'same' padding\n",
    "                nobias=False,  # default, have bias\n",
    "                initialW=init_weights,\n",
    "            )\n",
    "            self.conv_layer1 = L.Convolution2D(None, 64, 3, 1, 1, False, init_weights)\n",
    "            self.conv_layer2 = L.Convolution2D(None, 64, 3, 2, 1, False, init_weights)\n",
    "            self.conv_layer3 = L.Convolution2D(None, 128, 3, 1, 1, False, init_weights)\n",
    "            self.conv_layer4 = L.Convolution2D(None, 128, 3, 2, 1, False, init_weights)\n",
    "            self.conv_layer5 = L.Convolution2D(None, 256, 3, 1, 1, False, init_weights)\n",
    "            self.conv_layer6 = L.Convolution2D(None, 256, 3, 2, 1, False, init_weights)\n",
    "            self.conv_layer7 = L.Convolution2D(None, 512, 3, 1, 1, False, init_weights)\n",
    "            self.conv_layer8 = L.Convolution2D(None, 512, 3, 2, 1, False, init_weights)\n",
    "\n",
    "            self.batch_norm1 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "            self.batch_norm2 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "            self.batch_norm3 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "            self.batch_norm4 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "            self.batch_norm5 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "            self.batch_norm6 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "            self.batch_norm7 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "            self.batch_norm8 = L.BatchNormalization(axis=(0, 2, 3), eps=0.001)\n",
    "\n",
    "            self.linear_1 = L.Linear(in_size=None, out_size=1024, initialW=init_weights)\n",
    "            self.linear_2 = L.Linear(in_size=None, out_size=1, initialW=init_weights)\n",
    "\n",
    "    def forward(self, inputs: dict):\n",
    "        \"\"\"\n",
    "        Forward computation, i.e. evaluate based on inputs\n",
    "\n",
    "        Input dictionary needs to have keys \"x\"\n",
    "        \"\"\"\n",
    "\n",
    "        # 1st part\n",
    "        # Convolutonal Block without Batch Normalization k3n64s1\n",
    "        a0 = self.conv_layer0(x=inputs[\"x\"])\n",
    "        a0 = F.leaky_relu(x=a0, slope=0.2)\n",
    "\n",
    "        # 2nd part\n",
    "        # Convolutional Blocks with Batch Normalization k3n{64*f}s{1or2}\n",
    "        a1 = self.conv_layer1(x=a0)\n",
    "        a1 = self.batch_norm1(x=a1)\n",
    "        a1 = F.leaky_relu(x=a1, slope=0.2)\n",
    "        a2 = self.conv_layer2(x=a1)\n",
    "        a2 = self.batch_norm2(x=a2)\n",
    "        a2 = F.leaky_relu(x=a2, slope=0.2)\n",
    "        a3 = self.conv_layer3(x=a2)\n",
    "        a3 = self.batch_norm3(x=a3)\n",
    "        a3 = F.leaky_relu(x=a3, slope=0.2)\n",
    "        a4 = self.conv_layer4(x=a3)\n",
    "        a4 = self.batch_norm4(x=a4)\n",
    "        a4 = F.leaky_relu(x=a4, slope=0.2)\n",
    "        a5 = self.conv_layer5(x=a4)\n",
    "        a5 = self.batch_norm5(x=a5)\n",
    "        a5 = F.leaky_relu(x=a5, slope=0.2)\n",
    "        a6 = self.conv_layer6(x=a5)\n",
    "        a6 = self.batch_norm6(x=a6)\n",
    "        a6 = F.leaky_relu(x=a6, slope=0.2)\n",
    "        a7 = self.conv_layer7(x=a6)\n",
    "        a7 = self.batch_norm7(x=a7)\n",
    "        a7 = F.leaky_relu(x=a7, slope=0.2)\n",
    "        a8 = self.conv_layer8(x=a7)\n",
    "        a8 = self.batch_norm8(x=a8)\n",
    "        a8 = F.leaky_relu(x=a8, slope=0.2)\n",
    "\n",
    "        # 3rd part\n",
    "        # Flatten, Dense (Fully Connected) Layers and Output\n",
    "        a9 = F.reshape(x=a8, shape=(len(a8), -1))  # flatten while keeping batch_size\n",
    "        a9 = self.linear_1(x=a9)\n",
    "        a9 = F.leaky_relu(x=a9, slope=0.2)\n",
    "        a10 = self.linear_2(x=a9)\n",
    "        # a10 = F.sigmoid(x=a10)  # no sigmoid activation, as it is in the loss function\n",
    "\n",
    "        return a10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def discriminator_network(\n",
    "    input_shape: typing.Tuple[int, int, int] = (32, 32, 1)\n",
    ") -> keras.engine.network.Network:\n",
    "    \"\"\"\n",
    "    The discriminator network which is a convolutional neural network.\n",
    "    Takes ONE high resolution input image and predicts whether it is\n",
    "    real or fake on a scale of 0 to 1, where 0 is fake and 1 is real.\n",
    "\n",
    "    >>> discriminator_network().input_shape\n",
    "    (None, 32, 32, 1)\n",
    "    >>> discriminator_network().output_shape\n",
    "    (None, 1)\n",
    "    >>> discriminator_network().count_params()\n",
    "    6828033\n",
    "    \"\"\"\n",
    "\n",
    "    ## Input images\n",
    "    inp = Input(shape=input_shape)  # high resolution/groundtruth image to discriminate\n",
    "    assert inp.shape.ndims == 4  # needs to be shape like (?,32,32,1) for 8x8 grid\n",
    "\n",
    "    # 1st part\n",
    "    # Convolutonal Block without Batch Normalization k3n64s1\n",
    "    X = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\")(inp)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "\n",
    "    # 2nd part\n",
    "    # Convolutional Blocks with Batch Normalization k3n{64*f}s{1or2}\n",
    "    for f, s in zip([1, 1, 2, 2, 4, 4, 8, 8], [1, 2, 1, 2, 1, 2, 1, 2]):\n",
    "        X = Conv2D(filters=64 * f, kernel_size=(3, 3), strides=(s, s), padding=\"same\")(\n",
    "            X\n",
    "        )\n",
    "        X = BatchNormalization()(X)\n",
    "        X = LeakyReLU(alpha=0.2)(X)\n",
    "\n",
    "    # 3rd part\n",
    "    # Flatten, Dense (Fully Connected) Layers and Output\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(units=1024)(X)  # ??!! Flatten?\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    outp = Dense(units=1, activation=\"sigmoid\", name=\"discriminator_output\")(X)\n",
    "\n",
    "    # Create neural network with input highres/groundtruth images, output validity 0/1\n",
    "    network = keras.engine.network.Network(\n",
    "        inputs=[inp], outputs=[outp], name=\"discriminator_network\"\n",
    "    )\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Define Loss function and Metrics for the Generator and Discriminator Networks\n",
    "\n",
    "Now we define the Perceptual Loss function for our Generator and Discriminator neural network models, where:\n",
    "\n",
    "$$Perceptual Loss = Content Loss + Adversarial Loss$$\n",
    "\n",
    "![Perceptual Loss in an Enhanced Super Resolution Generative Adversarial Network](https://yuml.me/db58d683.png)\n",
    "\n",
    "<!--\n",
    "[LowRes-Inputs]-Generator>[SuperResolution_DEM]\n",
    "[SuperResolution_DEM]-.->[note:Content-Loss|MeanAbsoluteError{bg:yellow}]\n",
    "[HighRes-Groundtruth_DEM]-.->[note:Content-Loss]\n",
    "[SuperResolution_DEM]-Discriminator>[False_or_True_Prediction]\n",
    "[HighRes-Groundtruth_DEM]-Discriminator>[False_or_True_Prediction]\n",
    "[False_or_True_Prediction]<->[False_or_True_Label]\n",
    "[False_or_True_Prediction]-.->[note:Adversarial-Loss|BinaryCrossEntropy{bg:yellow}]\n",
    "[False_or_True_Label]-.->[note:Adversarial-Loss]\n",
    "[note:Content-Loss]-.->[note:Perceptual-Loss{bg:gold}]\n",
    "[note:Adversarial-Loss]-.->[note:Perceptual-Loss{bg:gold}]\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Loss\n",
    "\n",
    "The original SRGAN paper by [Ledig et al. 2017](https://arxiv.org/abs/1609.04802v5) calculates *Content Loss* based on the ReLU activation layers of the pre-trained 19 layer VGG network.\n",
    "The implementation below is less advanced, simply using an L1 loss, i.e., a pixel-wise [Mean Absolute Error (MAE) loss](https://keras.io/losses/#mean_absolute_error) as the *Content Loss*.\n",
    "Specifically, the *Content Loss* is calculated as the MAE difference between the output of the generator model (i.e. the predicted Super Resolution Image) and that of the groundtruth image (i.e. the true High Resolution Image).\n",
    "\n",
    "$$ e_i = ||G(x_{i}) - y_i||_{1} $$\n",
    "\n",
    "$$ Loss_{Content} = Mean Absolute Error = \\dfrac{1}{n} \\sum\\limits_{i=1}^n e_i $$\n",
    "\n",
    "where $G(x_{i})$ is the Generator Network's predicted value, and $y_i$ is the groundtruth value, respectively at pixel $i$.\n",
    "$e_i$ thus represents the absolute error (L1 loss) (denoted by $||\\dots||_{1}$) between the predicted and groundtruth value.\n",
    "We then sum all the pixel-wise errors $e_i,\\dots,e_n$ and divide by the number of pixels $n$ to get the Arithmetic Mean $\\dfrac{1}{n} \\sum\\limits_{i=1}^n$ of our error which is our *Content Loss*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Loss\n",
    "\n",
    "The *Adversarial Loss* or *Generative Loss* (confusing I know) is the same as in the original SRGAN paper.\n",
    "It is defined based on the probabilities of the discriminator believing that the reconstructed Super Resolution Image is a natural High Resolution Image.\n",
    "The implementation below uses the [Binary CrossEntropy loss](https://keras.io/losses/#binary_crossentropy).\n",
    "Specifically, this *Adversarial Loss* is calculated between the output of the discriminator model (a value between 0 and 1) and that of the groundtruth label (a boolean value of either 0 or 1).\n",
    "\n",
    "$$ Loss_{Adversarial} = Binary Cross Entropy Loss = -\\dfrac{1}{n} \\sum\\limits_{i=1}^n ( y_i ln(\\sigma(x_i)) + (1-y_i) ln(1 - \\sigma(x_i) ) $$\n",
    "\n",
    "where $\\sigma$ is the [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) activation function, $\\sigma = \\dfrac{1}{1+e^{-x}} = \\dfrac{e^x}{e^x+1}$, $y_i$ is the groundtruth label (1 for real, 0 for fake) and $x_i$ is the prediction (before sigmoid activation is applied), all respectively at pixel $i$.\n",
    "\n",
    "$\\sigma(x)$ is basically the sigmoid activated output from a Standard Discriminator neural network, which some people also denote as $D(.)$.\n",
    "Technically, some people also write $D(x) = \\sigma(C(x))$, where $C(x)$ is the raw, non-transformed output from the Discriminator neural network (i.e. no sigmoid activation applied) on the input data $x$.\n",
    "For simplicity, we now denote $C(x)$ simply as $x$ in the following equations, i.e. using $\\sigma(x)$ to replace $\\sigma(C(x))$.\n",
    "\n",
    "Again, the [Binary Cross Entropy Loss](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression) calculated on one pixel is defined as follows:\n",
    "\n",
    "$$ -( y ln(\\sigma(x)) + (1-y) ln(1 - \\sigma(x) )$$\n",
    "\n",
    "With the full expansion as such:\n",
    "\n",
    "$$ -\\bigg[ y ln\\big(\\dfrac{e^x}{e^x+1}\\big) + (1-y) ln\\big(1 - \\dfrac{e^x}{e^x+1}\\big) \\bigg] $$\n",
    "\n",
    "The above equation is mathematically equivalent to the one below, and can be derived using [Logarithm rules](https://en.wikipedia.org/wiki/Logarithm#Product,_quotient,_power,_and_root) such as the Power Rule and Product Rule, and using the fact that $ln(e)=1$ and $ln(1)=0$:\n",
    "\n",
    "$$ -[ xy - ln(1+e^x) ] $$\n",
    "\n",
    "However, this reformed equation is numerically unstable (see discussion [here](https://www.reddit.com/r/MachineLearning/comments/4euzmk/logsumexp_for_logistic_regression/)), and is good for values of $x<0$.\n",
    "For values of $x>=0$, there is an alternative representation which we can derive:\n",
    "\n",
    "$$ -[ xy - ln(1+e^x) - x + x ] $$\n",
    "$$ -[ x(y-1) - ln(1 + e^x) + ln(e^x) ] $$\n",
    "$$ -\\bigg[ x(y-1) - ln\\big(\\dfrac{e^x}{1+e^x}\\big) \\bigg] $$\n",
    "$$ -\\bigg[ x(y-1) - ln\\big(\\dfrac{1}{1+e^{-x}}\\big) \\bigg] $$\n",
    "$$ - [ x(y-1) - ln(1) + ln(1+e^{-x}) ] $$\n",
    "$$ - [ x(y-1) + ln(1+e^{-x}) $$\n",
    "\n",
    "In order to have a numerically stable function that works for both $x<0$ and $x>=0$, we can write it like so as in Caffe's implementation:\n",
    "\n",
    "$$ -[ x(y - 1_{x>=0} - ln(1+e^{x-2x\\cdot1_{x>=0}}) ] $$\n",
    "\n",
    "Alternatively, Chainer does it like so:\n",
    "\n",
    "$$ -[ x(y - 1_{x>=0} - ln(1+e^{-|x|}) ] $$\n",
    "\n",
    "Or in Python code (the Chainer implemention from [here](https://github.com/chainer/chainer/blob/v6.0.0b1/chainer/functions/loss/sigmoid_cross_entropy.py#L41-L44)), bearing in mind that the natural logarithm $ln$ is `np.log` in Numpy:\n",
    "\n",
    "```python\n",
    "    sigmoidbinarycrossentropyloss = -(x * (y - (x >= 0)) - np.log1p(np.exp(-np.abs(x))))\n",
    "```\n",
    "\n",
    "See also how [Pytorch](https://pytorch.org/docs/stable/nn.html?highlight=bcewithlogitsloss#torch.nn.BCEWithLogitsLoss) and [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits) implements this in a numerically stable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def calculate_generator_loss(\n",
    "    y_pred: chainer.variable.Variable,\n",
    "    y_true: cupy.ndarray,\n",
    "    pred_labels: cupy.ndarray,\n",
    "    true_labels: cupy.ndarray,\n",
    ") -> chainer.variable.Variable:\n",
    "    \"\"\"\n",
    "    Calculate the batchwise loss of the Generator Network.\n",
    "\n",
    "    >>> calculate_generator_loss(\n",
    "    ...     y_pred=chainer.variable.Variable(data=np.ones(shape=(2, 1, 3, 3))),\n",
    "    ...     y_true=np.full(shape=(2, 1, 3, 3), fill_value=10.0),\n",
    "    ...     pred_labels=np.zeros(shape=(2, 1, 3, 3)),\n",
    "    ...     true_labels=np.ones(shape=(2, 1, 3, 3)).astype(np.int32),\n",
    "    ... )\n",
    "    variable(9.69314718)\n",
    "    \"\"\"\n",
    "    # Content Loss (L1, Mean Absolute Error)\n",
    "    content_loss = F.mean_absolute_error(x0=y_pred, x1=y_true)\n",
    "\n",
    "    # Adversarial Loss\n",
    "    adversarial_loss = F.sigmoid_cross_entropy(x=pred_labels, t=true_labels)\n",
    "\n",
    "    # Get generator loss\n",
    "    g_loss = (1 * content_loss) + (1 * adversarial_loss)\n",
    "    g_loss\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def psnr(\n",
    "    y_true: cupy.ndarray, y_pred: cupy.ndarray, data_range=2 ** 32\n",
    ") -> cupy.ndarray:\n",
    "    \"\"\"\n",
    "    Peak Signal-Noise Ratio (PSNR) metric, calculated batchwise.\n",
    "    See https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio#Definition\n",
    "\n",
    "    Can take in either numpy (CPU) or cupy (GPU) arrays as input.\n",
    "    Implementation is same as skimage.measure.compare_psnr with data_range=2**32\n",
    "\n",
    "    >>> psnr(\n",
    "    ...     y_true=np.ones(shape=(2, 1, 3, 3)),\n",
    "    ...     y_pred=np.full(shape=(2, 1, 3, 3), fill_value=2),\n",
    "    ... )\n",
    "    192.65919722494797\n",
    "    \"\"\"\n",
    "    xp = chainer.backend.get_array_module(y_true)\n",
    "\n",
    "    # Calculate Mean Squred Error along predetermined axes\n",
    "    mse = xp.mean(xp.square(xp.subtract(y_pred, y_true)), axis=None)\n",
    "\n",
    "    # Calculate Peak Signal-Noise Ratio, setting MAX_I as 2^32, i.e. max for int32\n",
    "    return xp.multiply(20, xp.log10(data_range / xp.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def calculate_discriminator_loss(\n",
    "    y_pred: chainer.variable.Variable, y_true: cupy.ndarray\n",
    ") -> chainer.variable.Variable:\n",
    "    \"\"\"\n",
    "    Calculate the batchwise loss of the Discriminator Network.\n",
    "\n",
    "    Original formula:\n",
    "    -(y * np.log(sigmoid(x)) + (1 - y) * np.log(1 - sigmoid(x)))\n",
    "\n",
    "    Numerically stable formula:\n",
    "    -(x * (y - (x >= 0)) - np.log1p(np.exp(-np.abs(x))))\n",
    "\n",
    "    >>> calculate_discriminator_loss(\n",
    "    ...     y_pred=chainer.variable.Variable(data=np.array([[0.5], [1.5], [-0.5]])),\n",
    "    ...     y_true=np.array([[0], [1], [0]]),\n",
    "    ... )\n",
    "    variable(0.54985575)\n",
    "    \"\"\"\n",
    "\n",
    "    # Binary Cross-Entropy Loss\n",
    "    bce_loss = F.sigmoid_cross_entropy(x=y_pred, t=y_true)\n",
    "\n",
    "    # Get discriminator loss\n",
    "    d_loss = bce_loss\n",
    "\n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def compile_srgan_model(\n",
    "    g_network: keras.engine.network.Network,\n",
    "    d_network: keras.engine.network.Network,\n",
    "    metrics: typing.Dict[str, str] = None,\n",
    ") -> typing.Dict[str, keras.engine.training.Model]:\n",
    "    \"\"\"\n",
    "    Creates a Super Resolution Generative Adversarial Network (SRGAN)\n",
    "    by joining a generator network with a discriminator network.\n",
    "\n",
    "    Returns a dictionary containing:\n",
    "    1) generator model (trainable, not compiled)\n",
    "    2) discriminator model (trainable, compiled)\n",
    "    3) srgan model (trainable generator, untrainable discriminator, compiled)\n",
    "\n",
    "    The SRGAN model will be compiled with an optimizer (e.g. Adam)\n",
    "    and have separate loss functions and metrics for its\n",
    "    generator and discriminator component.\n",
    "\n",
    "    >>> metrics = {\"generator_network\": 'mse', \"discriminator_network\": 'accuracy'}\n",
    "    >>> models = compile_srgan_model(\n",
    "    ...     g_network=generator_network(),\n",
    "    ...     d_network=discriminator_network(),\n",
    "    ...     metrics=metrics,\n",
    "    ... )\n",
    "    >>> models['discriminator_model'].trainable\n",
    "    True\n",
    "    >>> models['srgan_model'].get_layer(name='generator_network').trainable\n",
    "    True\n",
    "    >>> models['srgan_model'].get_layer(name='discriminator_network').trainable\n",
    "    False\n",
    "    >>> models['srgan_model'].count_params()\n",
    "    8432962\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that our neural networks are named properly\n",
    "    assert g_network.name == \"generator_network\"\n",
    "    assert d_network.name == \"discriminator_network\"\n",
    "    assert g_network.trainable == True  # check that generator is trainable\n",
    "    assert d_network.trainable == True  # check that discriminator is trainable\n",
    "\n",
    "    ## Both trainable\n",
    "    # Create keras models (trainable) out of the networks (graph only)\n",
    "    g_model = Model(\n",
    "        inputs=g_network.inputs, outputs=g_network.outputs, name=\"generator_model\"\n",
    "    )\n",
    "    d_model = Model(\n",
    "        inputs=d_network.inputs, outputs=d_network.outputs, name=\"discriminator_model\"\n",
    "    )\n",
    "    d_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "        loss={\"discriminator_output\": keras.losses.binary_crossentropy},\n",
    "    )\n",
    "\n",
    "    ## One trainable (generator), one untrainable (discriminator)\n",
    "    # Connect Generator Network to Discriminator Network\n",
    "    g_out = g_network(inputs=g_network.inputs)  # g_in --(g_network)--> g_out\n",
    "    d_out = d_network(inputs=g_out)  # g_out --(d_network)--> d_out\n",
    "\n",
    "    # Create and Compile the Super Resolution Generative Adversarial Network Model!\n",
    "    model = Model(inputs=g_network.inputs, outputs=[g_out, d_out])\n",
    "    model.get_layer(\n",
    "        name=\"discriminator_network\"\n",
    "    ).trainable = False  # combined model should not train discriminator\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "        loss={\n",
    "            \"generator_network\": keras.losses.mean_absolute_error,\n",
    "            \"discriminator_network\": keras.losses.binary_crossentropy,\n",
    "        },\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"generator_model\": g_model,\n",
    "        \"discriminator_model\": d_model,\n",
    "        \"srgan_model\": model,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the models\n",
    "generator_model = GeneratorModel(\n",
    "    inblock_class=DeepbedmapInputBlock,\n",
    "    resblock_class=ResidualBlock,\n",
    "    num_residual_blocks=16,\n",
    ")\n",
    "discriminator_model = DiscriminatorModel()\n",
    "\n",
    "# Transfer models to GPU if available\n",
    "if xp == cupy:  # Check if CuPy was loaded, i.e. GPU is available\n",
    "    generator_model.to_gpu(device=0)\n",
    "    discriminator_model.to_gpu(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer, using Adam\n",
    "generator_optimizer = chainer.optimizers.Adam(alpha=0.001, eps=1e-7).setup(\n",
    "    link=generator_model\n",
    ")\n",
    "discriminator_optimizer = chainer.optimizers.Adam(alpha=0.001, eps=1e-7).setup(\n",
    "    link=discriminator_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train model\n",
    "\n",
    "[Gherkin](https://en.wikipedia.org/wiki/Gherkin_(language))/Plain English statement at what the Super-Resolution Generative Adversarial Network below does\n",
    "\n",
    "```gherkin\n",
    "    # language: en\n",
    "    Feature: SRGAN DeepBedMap\n",
    "      In order to create a great map of Antarctica's bed\n",
    "      As a data scientist,\n",
    "      We want a model that produces realistic images from many open datasets\n",
    "\n",
    "      Scenario: Train discriminator to beat generator\n",
    "        Given fake generated images from a generator\n",
    "          And real groundtruth images\n",
    "         When the two sets of images are fed into the discriminator\n",
    "         Then the discriminator should know the fakes from the real images\n",
    "\n",
    "      Scenario: Train generator to fool discriminator\n",
    "        Given fake generated images from a generator\n",
    "          And what we think the discriminator believes is real\n",
    "         When we compare the fake images to the real ones\n",
    "         Then the generator should learn to create a more authentic looking image\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def train_discriminator(\n",
    "    models: typing.Dict[str, keras.engine.training.Model],\n",
    "    generator_inputs: typing.List[np.ndarray],\n",
    "    groundtruth_images: np.ndarray,\n",
    "    verbose: int = 1,\n",
    ") -> (typing.Dict[str, keras.engine.training.Model], list):\n",
    "    \"\"\"\n",
    "    Trains the Discriminator within a Super Resolution Generative Adversarial Network.\n",
    "    Discriminator is trainable, Generator is not trained (only produces predictions).\n",
    "\n",
    "    Steps:\n",
    "    - Generator produces fake images\n",
    "    - Fake images combined with real groundtruth images\n",
    "    - Discriminator trained with these images and their Fake(0)/Real(1) labels\n",
    "\n",
    "    >>> generator_inputs = [\n",
    "    ...     np.random.RandomState(seed=42).rand(32, s, s, 1) for s in [10, 100, 20]\n",
    "    ... ]\n",
    "    >>> groundtruth_images = np.random.RandomState(seed=42).rand(32,32,32,1)\n",
    "    >>> models = compile_srgan_model(\n",
    "    ...     g_network=generator_network(), d_network=discriminator_network()\n",
    "    ... )\n",
    "\n",
    "    >>> d_weight0 = K.eval(models['discriminator_model'].weights[0][0,0,0,0])\n",
    "    >>> _, _ = train_discriminator(\n",
    "    ...     models=models,\n",
    "    ...     generator_inputs=generator_inputs,\n",
    "    ...     groundtruth_images=groundtruth_images,\n",
    "    ...     verbose=0,\n",
    "    ... )\n",
    "    >>> d_weight1 = K.eval(models['discriminator_model'].weights[0][0,0,0,0])\n",
    "\n",
    "    >>> d_weight0 != d_weight1  #check that training has occurred (i.e. weights changed)\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    # hardcoded check that we are passing in 3 numpy arrays as input\n",
    "    assert len(generator_inputs) == 3\n",
    "    # check that X_data and W1_data have same length (batch size)\n",
    "    assert generator_inputs[0].shape[0] == generator_inputs[1].shape[0]\n",
    "    # check that X_data and W2_data have same length (batch size)\n",
    "    assert generator_inputs[0].shape[0] == generator_inputs[2].shape[0]\n",
    "\n",
    "    # @pytest.fixture\n",
    "    g_model = models[\"generator_model\"]\n",
    "    d_model = models[\"discriminator_model\"]\n",
    "\n",
    "    # @given(\"fake generated images from a generator\")\n",
    "    fake_images = g_model.predict(x=generator_inputs, batch_size=32)\n",
    "    fake_labels = np.zeros(shape=len(generator_inputs[0]))\n",
    "\n",
    "    # @given(\"real groundtruth images\")\n",
    "    real_images = groundtruth_images  # groundtruth images i.e. Y_data\n",
    "    real_labels = np.ones(shape=len(groundtruth_images))\n",
    "\n",
    "    # @when(\"the two sets of images are fed into the discriminator\")\n",
    "    images = np.concatenate([fake_images, real_images])\n",
    "    labels = np.concatenate([fake_labels, real_labels])\n",
    "    assert d_model.trainable == True\n",
    "    d_metrics = d_model.fit(\n",
    "        x=images, y=labels, epochs=1, batch_size=32, shuffle=True, verbose=verbose\n",
    "    ).history\n",
    "\n",
    "    # @then(\"the discriminator should know the fakes from the real images\")\n",
    "    # assert d_weight0 != d_weight1  # check that training occurred i.e. weights changed\n",
    "\n",
    "    return models, d_metrics[\"loss\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def train_eval_generator(\n",
    "    input_arrays: typing.Dict[str, cupy.ndarray],\n",
    "    g_model,\n",
    "    d_model,\n",
    "    g_optimizer=None,\n",
    "    train: bool = True,\n",
    ") -> (float, float):\n",
    "    \"\"\"\n",
    "    Evaluates and/or trains the Generator for one minibatch\n",
    "    within a Super Resolution Generative Adversarial Network.\n",
    "    Discriminator is not trainable, Generator is trained.\n",
    "\n",
    "    If train is set to False, only forward pass is run, i.e. evaluation/prediction only\n",
    "    If train is set to True, forward and backward pass are run, i.e. train with backprop\n",
    "\n",
    "    Steps:\n",
    "    - Generator produces fake images\n",
    "    - Fake images compared with real groundtruth images\n",
    "    - Generator is trained to be more like real image\n",
    "\n",
    "    >>> train_arrays = {\n",
    "    ...     \"X\": np.random.RandomState(seed=42).rand(2, 1, 10, 10).astype(np.float32),\n",
    "    ...     \"W1\": np.random.RandomState(seed=42).rand(2, 1, 100, 100).astype(np.float32),\n",
    "    ...     \"W2\": np.random.RandomState(seed=42).rand(2, 1, 20, 20).astype(np.float32),\n",
    "    ...     \"Y\": np.random.RandomState(seed=42).rand(2, 1, 32, 32).astype(np.float32),\n",
    "    ... }\n",
    "    >>> generator_model = GeneratorModel(\n",
    "    ...     inblock_class=DeepbedmapInputBlock,\n",
    "    ...     resblock_class=ResidualBlock,\n",
    "    ...     num_residual_blocks=1,\n",
    "    ... )\n",
    "    >>> generator_optimizer = chainer.optimizers.Adam(alpha=0.001, eps=1e-7).setup(\n",
    "    ...     link=generator_model\n",
    "    ... )\n",
    "    >>> discriminator_model = DiscriminatorModel()\n",
    "\n",
    "    >>> g_weight0 = [g for g in generator_model.params()][0][0, 0, 0, 0].array\n",
    "    >>> _ = train_eval_generator(\n",
    "    ...     input_arrays=train_arrays,\n",
    "    ...     g_model=generator_model,\n",
    "    ...     d_model=discriminator_model,\n",
    "    ...     g_optimizer=generator_optimizer,\n",
    "    ... )\n",
    "    >>> g_weight1 = [g for g in generator_model.params()][0][0, 0, 0, 0].array\n",
    "    >>> g_weight0 != g_weight1  #check that training has occurred (i.e. weights changed)\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    # @pytest.fixture\n",
    "    if train == True:\n",
    "        assert g_optimizer is not None  # Optimizer required for neural network training\n",
    "    xp = chainer.backend.get_array_module(input_arrays[\"Y\"])\n",
    "\n",
    "    # @given(\"fake generated images from a generator\")\n",
    "    generator_inputs = {\n",
    "        \"x\": input_arrays[\"X\"],\n",
    "        \"w1\": input_arrays[\"W1\"],\n",
    "        \"w2\": input_arrays[\"W2\"],\n",
    "    }\n",
    "    y_pred = g_model.forward(inputs=generator_inputs)\n",
    "    predicted_labels = d_model.forward(inputs={\"x\": y_pred}).array\n",
    "\n",
    "    # @given(\"what we think the discriminator believes is real\")\n",
    "    groundtruth_images = input_arrays[\"Y\"]\n",
    "    groundtruth_labels = xp.ones(shape=(len(groundtruth_images), 1)).astype(xp.int32)\n",
    "\n",
    "    # @when(\"we compare the fake images to the real ones\")\n",
    "    g_loss = calculate_generator_loss(\n",
    "        y_pred=y_pred,\n",
    "        y_true=groundtruth_images,\n",
    "        pred_labels=predicted_labels,\n",
    "        true_labels=groundtruth_labels,\n",
    "    )\n",
    "    g_psnr = psnr(y_pred=y_pred.array, y_true=groundtruth_images)\n",
    "\n",
    "    # @then(\"the generator should learn to create a more authentic looking image\")\n",
    "    if train == True:\n",
    "        g_model.cleargrads()  # clear/zero all gradients\n",
    "        g_loss.backward()  # renew gradients\n",
    "        g_optimizer.update()  # backpropagate the loss using optimizer\n",
    "\n",
    "    return float(g_loss.array), float(g_psnr)  # return generator loss and metric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [05:39<00:00,  3.41s/epoch, generator_loss=0.79, generator_psnr=161, val_generator_loss=0.893, val_generator_psnr=160]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "metric_names = [\"generator_loss\", \"generator_psnr\"]\n",
    "columns = metric_names + [f\"val_{metric_name}\" for metric_name in metric_names]\n",
    "dataframe = pd.DataFrame(index=np.arange(epochs), columns=columns)\n",
    "progressbar = tqdm.tqdm(unit=\"epoch\", total=epochs, position=0)\n",
    "\n",
    "train_iter.reset()\n",
    "dev_iter.reset()\n",
    "\n",
    "for i in range(epochs):\n",
    "    metrics_dict = {mn: [] for mn in columns}  # reset metrics dictionary\n",
    "\n",
    "    ## Training on training dataset\n",
    "    while i == train_iter.epoch:  # while we are in epoch i, run minibatch training\n",
    "        train_batch = train_iter.next()\n",
    "        train_arrays = chainer.dataset.concat_examples(batch=train_batch)\n",
    "        ## Part 1 - Train Discriminator\n",
    "\n",
    "        ## Part 2 - Train Generator\n",
    "        g_train_loss, g_train_psnr = train_eval_generator(\n",
    "            input_arrays=train_arrays,\n",
    "            g_model=generator_model,\n",
    "            d_model=None,\n",
    "            g_optimizer=generator_optimizer,\n",
    "        )\n",
    "        metrics_dict[\"generator_loss\"].append(g_train_loss)\n",
    "        metrics_dict[\"generator_psnr\"].append(g_train_psnr)\n",
    "\n",
    "    ## Evaluation on development dataset\n",
    "    while i == dev_iter.epoch:  # while we are in epoch i, evaluate on each minibatch\n",
    "        dev_batch = dev_iter.next()\n",
    "        dev_arrays = chainer.dataset.concat_examples(batch=dev_batch)\n",
    "        ## Part 1 - Evaluate Discriminator\n",
    "\n",
    "        ## Part 2 - Evaluate Generator\n",
    "        g_dev_loss, g_dev_psnr = train_eval_generator(\n",
    "            input_arrays=dev_arrays, g_model=generator_model, d_model=None, train=False\n",
    "        )\n",
    "        metrics_dict[\"val_generator_loss\"].append(g_dev_loss)\n",
    "        metrics_dict[\"val_generator_psnr\"].append(g_dev_psnr)\n",
    "\n",
    "    ## Average loss and metrics across all minibatches\n",
    "    dataframe.loc[i] = (\n",
    "        np.mean(metrics_dict[\"generator_loss\"]),\n",
    "        np.mean(metrics_dict[\"generator_psnr\"]),\n",
    "        np.mean(metrics_dict[\"val_generator_loss\"]),\n",
    "        np.mean(metrics_dict[\"val_generator_psnr\"]),\n",
    "    )\n",
    "\n",
    "    ## Plot loss and metric information using livelossplot\n",
    "    livelossplot.draw_plot(\n",
    "        logs=dataframe.to_dict(orient=\"records\"),\n",
    "        metrics=metric_names,\n",
    "        max_cols=3,\n",
    "        figsize=(16, 9),\n",
    "        max_epoch=epochs,\n",
    "    )\n",
    "    progressbar.set_postfix(ordered_dict=dataframe.loc[i].to_dict())\n",
    "    experiment.log_metrics(dic=dataframe.loc[i].to_dict(), step=i)\n",
    "    progressbar.update(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "temp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-041f56ae3032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: temp"
     ]
    }
   ],
   "source": [
    "experiment.end()\n",
    "raise ValueError(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[\"generator_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(name=\"model/weights\", exist_ok=True)\n",
    "# generator model's parameter weights and architecture\n",
    "model.save(filepath=\"model/weights/srgan_generator_model.hdf5\")\n",
    "# just the model weights\n",
    "model.save_weights(filepath=\"model/weights/srgan_generator_model_weights.hdf5\")\n",
    "# just the model architecture\n",
    "with open(\"model/weights/srgan_generator_model_architecture.json\", \"w\") as json_file:\n",
    "    json_file.write(model.to_json(indent=2))\n",
    "\n",
    "# Upload model weights file to Comet.ML and finish Comet.ML experiment\n",
    "experiment.log_asset(\n",
    "    file_path=\"model/weights/srgan_generator_model_weights.hdf5\",\n",
    "    file_name=\"srgan_generator_model_weights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on independent test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_deepbedmap_test_result(test_filepath: str = \"highres/2007tx\"):\n",
    "    \"\"\"\n",
    "    Gets Root Mean Squared Error of elevation difference between\n",
    "    DeepBedMap topography and reference groundtruth xyz tracks\n",
    "    at a particular test region\n",
    "    \"\"\"\n",
    "    deepbedmap = _load_ipynb_modules(\"deepbedmap.ipynb\")\n",
    "\n",
    "    # Get groundtruth images, window_bounds and neural network input datasets\n",
    "    groundtruth, window_bound = deepbedmap.get_image_and_bounds(f\"{test_filepath}.nc\")\n",
    "    X_tile, W1_tile, W2_tile = deepbedmap.get_deepbedmap_model_inputs(\n",
    "        window_bound=window_bound\n",
    "    )\n",
    "\n",
    "    # Run input datasets through trained neural network model\n",
    "    model = deepbedmap.load_trained_model(model_inputs=(X_tile, W1_tile, W2_tile))\n",
    "    Y_hat = model.predict(x=[X_tile, W1_tile, W2_tile], verbose=1)\n",
    "\n",
    "    # Save infered deepbedmap to grid file(s)\n",
    "    deepbedmap.save_array_to_grid(\n",
    "        window_bound=window_bound, array=Y_hat, outfilepath=\"model/deepbedmap3\"\n",
    "    )\n",
    "\n",
    "    # Load xyz table for test region\n",
    "    data_prep = _load_ipynb_modules(\"data_prep.ipynb\")\n",
    "    track_test = data_prep.ascii_to_xyz(pipeline_file=f\"{test_filepath}.json\")\n",
    "    track_test.to_csv(\"track_test.xyz\", sep=\"\\t\", index=False)\n",
    "\n",
    "    # Get the elevation (z) value at specified x, y points along the groundtruth track\n",
    "    !gmt grdtrack track_test.xyz -Gmodel/deepbedmap3.nc -h1 -i0,1,2 > track_deepbedmap3.xyzi\n",
    "    df_deepbedmap3 = pd.read_table(\n",
    "        \"track_deepbedmap3.xyzi\", header=1, names=[\"x\", \"y\", \"z\", \"z_interpolated\"]\n",
    "    )\n",
    "\n",
    "    # Calculate elevation error between groundtruth xyz tracks and deepbedmap\n",
    "    df_deepbedmap3[\"error\"] = df_deepbedmap3.z_interpolated - df_deepbedmap3.z\n",
    "    rmse_deepbedmap3 = (df_deepbedmap3.error ** 2).mean() ** 0.5\n",
    "\n",
    "    return rmse_deepbedmap3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test = get_deepbedmap_test_result()\n",
    "print(f\"Experiment yielded Root Mean Square Error of {rmse_test:.2f} on test set\")\n",
    "experiment.log_metric(name=\"rmse_test\", value=rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "deepbedmap",
   "language": "python",
   "name": "deepbedmap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
